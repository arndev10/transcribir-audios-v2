# WhatsApp Audio Transcriber ğŸ¤â†’ğŸ“

MVP funcional de una aplicaciÃ³n web para transcribir audios de WhatsApp a texto usando Whisper local. Procesamiento 100% local, sin costos de API ni tokens.

## ğŸ¯ CaracterÃ­sticas

- âœ… Subida de audios en formatos `.ogg`, `.opus`, `.mp3`, `.wav`, `.m4a`, `.flac`
- âœ… TranscripciÃ³n a texto usando Whisper local (faster-whisper)
- âœ… DetecciÃ³n automÃ¡tica de idioma
- âœ… Interfaz web moderna y responsive
- âœ… Copiar texto al portapapeles
- âœ… Descargar transcripciÃ³n como archivo `.txt`
- âœ… Procesamiento 100% local (sin APIs externas)
- âœ… OptimizaciÃ³n para GPU (CUDA) cuando estÃ¡ disponible

## ğŸ§  TecnologÃ­as Usadas

### Backend
- **Python 3.10+**
- **FastAPI** - Framework web moderno y rÃ¡pido
- **faster-whisper** - ImplementaciÃ³n optimizada de Whisper
- **PyTorch** - Para soporte GPU/CUDA
- **Uvicorn** - Servidor ASGI

### Frontend
- **React 18** - Biblioteca UI
- **Vite** - Build tool y dev server
- **TailwindCSS** - Framework CSS utility-first

## ğŸ“ Estructura del Proyecto

```
whatsapp-audio-to-text/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # API FastAPI principal
â”‚   â”œâ”€â”€ whisper_service.py   # Servicio de transcripciÃ³n Whisper
â”‚   â””â”€â”€ requirements.txt     # Dependencias Python
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # Componentes React
â”‚   â”‚   â”œâ”€â”€ App.jsx         # Componente principal
â”‚   â”‚   â”œâ”€â”€ main.jsx        # Entry point
â”‚   â”‚   â””â”€â”€ index.css       # Estilos globales
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ tailwind.config.js
â””â”€â”€ README.md
```

## ğŸš€ CÃ³mo Ejecutar

### Prerrequisitos

- Python 3.10 o superior
- Node.js 18+ y npm
- (Opcional) CUDA toolkit si quieres usar GPU

### Backend

1. Navega a la carpeta `backend`:
```bash
cd backend
```

2. Crea un entorno virtual (recomendado):
```bash
python -m venv venv
```

3. Activa el entorno virtual:
   - Windows:
   ```bash
   venv\Scripts\activate
   ```
   - Linux/Mac:
   ```bash
   source venv/bin/activate
   ```

4. Instala las dependencias:
```bash
pip install -r requirements.txt
```

5. Ejecuta el servidor:
```bash
python main.py
```

El backend estarÃ¡ disponible en `http://localhost:8000`

**Nota**: La primera vez que ejecutes, faster-whisper descargarÃ¡ el modelo Whisper (modelo `medium` por defecto, ~1.4GB). Esto puede tardar unos minutos.

### Frontend

1. Navega a la carpeta `frontend`:
```bash
cd frontend
```

2. Instala las dependencias:
```bash
npm install
```

3. Ejecuta el servidor de desarrollo:
```bash
npm run dev
```

El frontend estarÃ¡ disponible en `http://localhost:5173`

## ğŸ“– Uso

1. Abre `http://localhost:5173` en tu navegador
2. Haz clic en el Ã¡rea de carga y selecciona un archivo de audio
3. Haz clic en "Transcribir Audio"
4. Espera a que se complete la transcripciÃ³n (puede tardar segÃºn la duraciÃ³n del audio)
5. Copia el texto o descÃ¡rgalo como archivo `.txt`

## âš™ï¸ ConfiguraciÃ³n

### Cambiar el Modelo de Whisper

En `backend/main.py`, puedes cambiar el tamaÃ±o del modelo:

```python
transcriber = WhisperTranscriber(
    model_size="large-v3",  # Opciones: tiny, base, small, medium, large-v2, large-v3
    device="auto",
    compute_type="auto"
)
```

**Modelos disponibles:**
- `tiny` - MÃ¡s rÃ¡pido, menos preciso (~75MB)
- `base` - Balance velocidad/precisiÃ³n (~142MB)
- `small` - Buen balance (~466MB)
- `medium` - Mejor precisiÃ³n (~1.4GB) - **Recomendado**
- `large-v2` - MÃ¡xima precisiÃ³n (~2.9GB)
- `large-v3` - Ãšltima versiÃ³n large (~2.9GB)

### Forzar CPU o GPU

En `backend/main.py`:

```python
transcriber = WhisperTranscriber(
    model_size="medium",
    device="cuda",  # o "cpu"
    compute_type="float16"  # o "int8" para CPU
)
```

## ğŸ§ª Endpoints API

### `GET /`
Endpoint de salud bÃ¡sico.

### `GET /health`
Endpoint de salud detallado con informaciÃ³n del modelo.

### `POST /transcribe`
Transcribe un archivo de audio.

**Request:**
- `file`: Archivo de audio (multipart/form-data)
- `language` (opcional): CÃ³digo de idioma (ej: `es`, `en`)

**Response:**
```json
{
  "text": "Texto transcrito completo...",
  "language": "es",
  "language_probability": 0.95,
  "duration": 45.2,
  "status": "success"
}
```

## ğŸ¨ Por QuÃ© Whisper Local?

1. **Costo Cero**: No hay costos de API ni tokens
2. **Privacidad**: Todo el procesamiento es local, tus audios nunca salen de tu mÃ¡quina
3. **Sin LÃ­mites**: No hay lÃ­mites de uso ni rate limiting
4. **Offline**: Funciona sin conexiÃ³n a internet
5. **Control Total**: Puedes ajustar parÃ¡metros y modelos segÃºn tus necesidades

## ğŸ—ºï¸ Roadmap

- [ ] Resumen automÃ¡tico de textos largos usando modelos locales
- [ ] Soporte para mÃºltiples archivos en batch
- [ ] Historial de transcripciones
- [ ] ExportaciÃ³n a diferentes formatos (PDF, DOCX)
- [ ] VersiÃ³n desktop con Tauri
- [ ] Mejoras en la UI/UX
- [ ] Soporte para timestamps en la transcripciÃ³n
- [ ] DetecciÃ³n de mÃºltiples hablantes

## ğŸ› SoluciÃ³n de Problemas

### Error: "CUDA out of memory"
- Reduce el tamaÃ±o del modelo (usa `small` o `base` en lugar de `medium`)
- O fuerza el uso de CPU: `device="cpu"`

### Error: "Model not found"
- La primera ejecuciÃ³n descarga el modelo automÃ¡ticamente
- AsegÃºrate de tener conexiÃ³n a internet la primera vez
- El modelo se guarda en `~/.cache/huggingface/`

### El backend no responde
- Verifica que el puerto 8000 estÃ© libre
- Revisa los logs del servidor para errores
- AsegÃºrate de que todas las dependencias estÃ©n instaladas

### El frontend no se conecta al backend
- Verifica que el backend estÃ© corriendo en `http://localhost:8000`
- Revisa la consola del navegador para errores CORS
- AsegÃºrate de que el proxy en `vite.config.js` estÃ© configurado correctamente

## ğŸ“ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible para uso en portfolio profesional.

## ğŸ‘¨â€ğŸ’» Autor

Desarrollado como MVP para demostraciÃ³n en portfolio profesional.

---

**Nota**: Este es un MVP funcional. Para producciÃ³n, considera agregar validaciones adicionales, manejo de errores mÃ¡s robusto, autenticaciÃ³n, y optimizaciones de rendimiento.

